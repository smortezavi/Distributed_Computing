{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"../Data/README.md\"\n",
    "word = sc.textFile(file_name).flatMap(lambda x : x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_word = word.map(lambda x : (len(x),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, u'#'),\n",
       " (6, u'Apache'),\n",
       " (5, u'Spark'),\n",
       " (0, u''),\n",
       " (5, u'Spark'),\n",
       " (2, u'is'),\n",
       " (1, u'a'),\n",
       " (4, u'fast'),\n",
       " (3, u'and'),\n",
       " (7, u'general')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_word.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  (68,\n",
       "   u',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,')),\n",
       " (112,\n",
       "  (1,\n",
       "   u'[Eclipse](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-Eclipse)')),\n",
       " (2,\n",
       "  (70,\n",
       "   u'is,It,in,R,,an,It,of,##,on,##,is,To,do,to,do,if,by,-T,in,is,at,an,##,to,is,to,##,if,##,in,To,of,Pi,to,to,be,or,to,on,to,or,to,an,if,is,in,of,if,no,##,is,be,on,to,or,##,to,to,in,of,to,at,on,of,##,to,in,an,on,to')),\n",
       " (4,\n",
       "  (47,\n",
       "   u'fast,APIs,that,data,also,rich,find,This,file,only,run:,(You,need,this,more,than,with,More,from,IDE,,also,also,with,will,when,This,URL,,with,with,also,name,Many,help,Once,[run,Note,uses,core,talk,HDFS,have,must,same,that,your,Hive,Hive')),\n",
       " (6,\n",
       "  (41,\n",
       "   u'Apache,system,Scala,,engine,graphs,GraphX,stream,Online,latest,guide,,README,thread,option,Maven,,builds,shell:,should,return,scala>,Python,prefer,Python,shell:,should,return,sample,MASTER,submit,\"yarn\",params,given.,built,,using:,Please,Hadoop,Hadoop,Please,Hadoop,Please,online,Spark.')),\n",
       " (8,\n",
       "  (33,\n",
       "   u'provides,supports,supports,[project,[project,contains,Building,detailed,command,,command,,Programs,programs,example:,locally.,variable,examples,examples,cluster.,mesos://,spark://,threads.,package.,programs,requires,guidance,Versions,systems.,versions,detailed,guidance,building,building,overview')),\n",
       " (96,\n",
       "  (1,\n",
       "   u'Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)')),\n",
       " (10,\n",
       "  (13,\n",
       "   u'high-level,downloaded,[\"Parallel,[\"Building,developing,`examples`,directory.,[params]`.,\"local[N]\",`examples`,individual,particular,particular')),\n",
       " (12, (4, u'higher-level,[\"Specifying,distribution,Thriftserver')),\n",
       " (18, (1, u'`./bin/run-example')),\n",
       " (14, (4, u'documentation,,Alternatively,,distributions.,[Configuration')),\n",
       " (16, (2, u'sc.parallelize(1,Hadoop-supported')),\n",
       " (82,\n",
       "  (1,\n",
       "   u'3\"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).')),\n",
       " (24, (2, u'MASTER=spark://host:7077,Spark](#building-spark).')),\n",
       " (26, (1, u'<http://spark.apache.org/>')),\n",
       " (62, (1, u'Guide](http://spark.apache.org/docs/latest/configuration.html)')),\n",
       " (1, (11, u'#,a,a,a,a,a,a,N,a,A,a')),\n",
       " (3,\n",
       "  (94,\n",
       "   u'and,for,Big,and,and,for,set,SQL,for,SQL,and,for,for,and,for,You,can,the,the,web,and,and,its,not,you,You,can,one,the,see,the,For,see,and,The,way,the,Try,the,you,you,can,use,the,And,run,the,>>>,the,run,one,use,For,run,the,You,can,set,the,can,run,and,run,one,run,You,can,use,the,the,For,the,are,can,run,see,the,how,for,the,and,the,you,the,the,the,for,for,for,and,the,the,for,how')),\n",
       " (5,\n",
       "  (60,\n",
       "   u'Spark,Spark,Data.,Java,,tools,Spark,MLlib,graph,Spark,Spark,basic,setup,Spark,Spark,built,using,build,Spark,clean,build,Spark,using,using,Maven,site,,Spark,using,Scala,Shell,start,using,Spark,Scala,which,1000:,Shell,which,1000:,Spark,comes,them,,YARN,,class,class,print,usage,Tests,first,Spark,tests,tests,About,Spark,other,build,Spark,runs.,refer,build,refer')),\n",
       " (65,\n",
       "  (1, u'Spark\"](http://spark.apache.org/docs/latest/building-spark.html).')),\n",
       " (7,\n",
       "  (36,\n",
       "   u'general,cluster,Python,,general,machine,[Apache,example,package,project,easiest,through,Python,,Example,several,<class>,SparkPi,example,running,\"local\",locally,thread,,locally,SparkPi,example,Running,Testing,module,,library,storage,Because,changed,Hadoop,,against,version,cluster,Hadoop,')),\n",
       " (9,\n",
       "  (20,\n",
       "   u'computing,optimized,analysis.,including,learning,,Streaming,including,programs,,build/mvn,pre-built,package.),available,following,following,instance:,[building,protocols,different,including,configure')),\n",
       " (11,\n",
       "  (10,\n",
       "   u'computation,DataFrames,,processing,,processing.,programming,-DskipTests,Interactive,Interactive,environment,abbreviated')),\n",
       " (13,\n",
       "  (8,\n",
       "   u'Documentation,instructions.,documentation,1000).count(),./bin/pyspark,documentation,Configuration,documentation')),\n",
       " (15, (1, u'./dev/run-tests')),\n",
       " (49, (1, u'page](http://spark.apache.org/documentation.html)')),\n",
       " (17, (3, u'./bin/spark-shell,./bin/run-example,./bin/run-example')),\n",
       " (115,\n",
       "  (1,\n",
       "   u'[IntelliJ](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-IntelliJ).')),\n",
       " (57, (1, u'wiki](https://cwiki.apache.org/confluence/display/SPARK).')),\n",
       " (33, (1, u'Maven](http://maven.apache.org/).')),\n",
       " (81,\n",
       "  (1,\n",
       "   u'tests](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools).')),\n",
       " (35, (1, u'sc.parallelize(range(1000)).count()'))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_word.combineByKey((lambda x : (1,x)), (lambda x,y : (x[0]+1, x[1]+\",\"+ y)), \n",
    "                      (lambda x, y : (x[0]+y[0], x[1]+\",\"+y[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
